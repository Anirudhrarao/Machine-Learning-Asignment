{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82261c80-b82e-42fe-8c8f-62885143b938",
   "metadata": {},
   "source": [
    "<h4 style='color:#98D8AA'>Q1. What is the role of feature selection in anomaly detection?</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fa6922-96ca-4baf-a50c-cf35603997ca",
   "metadata": {},
   "source": [
    "<div style='color:#2A2F4F;border:6px double black;border-radius:10px;padding:10px;background:#BFCCB5;'>\n",
    "The role of feature selection in anomaly detection is to identify and select the most relevant features that are useful in distinguishing between normal and anomalous data points. By reducing the dimensionality of the dataset, feature selection can improve the performance and efficiency of anomaly detection algorithms, reduce the risk of overfitting, and increase the interpretability of the results. Feature selection can be performed using various techniques such as correlation analysis, mutual information, principal component analysis (PCA), and recursive feature elimination (RFE).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca78d281-60d2-4944-8a74-df5728292341",
   "metadata": {},
   "source": [
    "<h4 style='color:#98D8AA'>Q2. What are some common evaluation metrics for anomaly detection algorithms and how are they\n",
    "computed?</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af73b29-e4e3-4a52-bc9e-ed60f2957bb7",
   "metadata": {},
   "source": [
    "<div style='color:#2A2F4F;border:6px double black;border-radius:10px;padding:10px;background:#BFCCB5;'>\n",
    "    Some common evaluation metrics for anomaly detection algorithms include precision, recall, F1-score, receiver operating characteristic (ROC) curve, and area under the curve (AUC). Precision measures the proportion of detected anomalies that are truly anomalies, while recall measures the proportion of true anomalies that are detected by the algorithm. F1-score is the harmonic mean of precision and recall, and provides a balanced measure of their performance. ROC curve plots the true positive rate (TPR) against the false positive rate (FPR) at different decision thresholds, while AUC measures the area under the ROC curve and provides an overall measure of the algorithm's ability to distinguish between normal and anomalous data points.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a64b1bc-c605-421f-97cc-578a64918734",
   "metadata": {},
   "source": [
    "<h4 style='color:#98D8AA'>Q3. What is DBSCAN and how does it work for clustering?</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee5922f-7230-4f71-8086-1f180b4eb321",
   "metadata": {},
   "source": [
    "<div style='color:#2A2F4F;border:6px double black;border-radius:10px;padding:10px;background:#BFCCB5;'>\n",
    "    DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a clustering algorithm that identifies clusters of data points based on their density in the feature space. DBSCAN works by defining a neighborhood around each data point and counting the number of points within the neighborhood. Data points that have a minimum number of neighbors within a specified radius are considered core points, and are used to form clusters. Data points that have fewer neighbors than the minimum threshold but are within the radius of a core point are considered border points and are assigned to the same cluster. Data points that have fewer neighbors than the minimum threshold and are not within the radius of any core point are considered noise points and are not assigned to any cluster. The key parameters of DBSCAN are the radius of the neighborhood (eps) and the minimum number of neighbors (min_samples) required to form a core point.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6046ad-f0ff-4fa8-8e55-92d4cbf82ee5",
   "metadata": {},
   "source": [
    "<h4 style='color:#98D8AA'>Q4. How does the epsilon parameter affect the performance of DBSCAN in detecting anomalies?</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd1bc82-cea0-4a80-a3b4-18bbe356dcb0",
   "metadata": {},
   "source": [
    "<div style='color:#2A2F4F;border:6px double black;border-radius:10px;padding:10px;background:#BFCCB5;'>\n",
    "The epsilon parameter in DBSCAN determines the radius of the neighborhood around each data point, and thus affects the ability of the algorithm to detect anomalies. A smaller value of epsilon leads to the formation of smaller clusters and more noise points, which may make it easier to detect anomalies that are isolated from the majority of the data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720e8bd1-638f-4d4b-9e49-cfeb04a0ed2c",
   "metadata": {},
   "source": [
    "<h4 style='color:#98D8AA'> Q5. What are the differences between the core, border, and noise points in DBSCAN, and how do they relate\n",
    "to anomaly detection?</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7600cd-b8e2-463a-bb9e-bde66c11d828",
   "metadata": {},
   "source": [
    "<div style='color:#2A2F4F;border:6px double black;border-radius:10px;padding:10px;background:#BFCCB5;'>\n",
    ". In DBSCAN, core points are data points that have a minimum number of neighbors within a specified radius, while border points have fewer neighbors than the minimum threshold but are within the radius of a core point, and noise points have fewer neighbors than the minimum threshold and are not within the radius of any core point. Core points and border points can be considered as part of normal data, while noise points can be considered as anomalies.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccf2375-36ea-411d-9031-734a7bbd36e8",
   "metadata": {},
   "source": [
    "<h4 style='color:#98D8AA'>Q6. How does DBSCAN detect anomalies and what are the key parameters involved in the process?</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99813587-2f9d-4d8c-8ea8-2cb084e01519",
   "metadata": {},
   "source": [
    "<div style='color:#2A2F4F;border:6px double black;border-radius:10px;padding:10px;background:#BFCCB5;'>\n",
    "DBSCAN detects anomalies by labeling data points that are not assigned to any cluster as noise points, which can be considered as anomalies. The key parameters involved in the process are the radius of the neighborhood (epsilon) and the minimum number of neighbors (min_samples) required to form a core point.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f1feab-e823-435e-962b-034a1846fc39",
   "metadata": {},
   "source": [
    "<h4 style='color:#98D8AA'>Q7. What is the make_circles package in scikit-learn used for?</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d390c5-6113-4189-b06f-5f4249029b49",
   "metadata": {},
   "source": [
    "<div style='color:#2A2F4F;border:6px double black;border-radius:10px;padding:10px;background:#BFCCB5;'>\n",
    "The make_circles package in scikit-learn is a utility function that generates a toy dataset of 2D points that form concentric circles with Gaussian noise. This dataset is often used to demonstrate clustering algorithms, including DBSCAN.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dbd8d4-e6fb-4724-92b2-bf4fa60c67a6",
   "metadata": {},
   "source": [
    "<h4 style='color:#98D8AA'>Q8. What are local outliers and global outliers, and how do they differ from each other?</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf1607b-5e89-4d13-8f70-67152ec8be61",
   "metadata": {},
   "source": [
    "<div style='color:#2A2F4F;border:6px double black;border-radius:10px;padding:10px;background:#BFCCB5;'>\n",
    "Local outliers are data points that are anomalous with respect to their local neighborhood, while global outliers are anomalous with respect to the entire dataset. Local outliers may not be detected by distance-based methods such as KNN, while global outliers may be easier to detect using such methods.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd365fb5-742d-4e06-945c-8bfc5e09b249",
   "metadata": {},
   "source": [
    "<h4 style='color:#98D8AA'>Q9. How can local outliers be detected using the Local Outlier Factor (LOF) algorithm?</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27432565-d44e-417c-b5bb-82c802e63074",
   "metadata": {},
   "source": [
    "<div style='color:#2A2F4F;border:6px double black;border-radius:10px;padding:10px;background:#BFCCB5;'>\n",
    " Local outliers can be detected using the Local Outlier Factor (LOF) algorithm by comparing the density of each data point to the density of its k-nearest neighbors. Data points with a significantly lower density than their neighbors are considered to be local outliers. The key parameter involved in the process is k, which determines the number of nearest neighbors used for density estimation.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3950e00d-1a00-475f-a651-e4798d2e25cf",
   "metadata": {},
   "source": [
    "<h4 style='color:#98D8AA'>Q10. How can global outliers be detected using the Isolation Forest algorithm?</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5d6a2d-6ce8-4ea4-9f8b-366cd984faa9",
   "metadata": {},
   "source": [
    "<div style='color:#2A2F4F;border:6px double black;border-radius:10px;padding:10px;background:#BFCCB5;'>\n",
    "Global outliers can be detected using the Isolation Forest algorithm by randomly selecting a feature and a split value for each tree in the forest, and then determining the number of splits required to isolate a data point. Data points that require fewer splits to isolate are considered to be more anomalous.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698ba148-eea1-45a3-b032-63e5a5a09d5a",
   "metadata": {},
   "source": [
    "<h4 style='color:#98D8AA'>Q11. What are some real-world applications where local outlier detection is more appropriate than global\n",
    "outlier detection, and vice versa?</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3258ea7-8742-4328-8401-339f9d06f562",
   "metadata": {},
   "source": [
    "<div style='color:#2A2F4F;border:6px double black;border-radius:10px;padding:10px;background:#BFCCB5;'>\n",
    "Local outlier detection is more appropriate than global outlier detection in situations where the anomalous behavior is localized and not representative of the entire dataset. Examples of such applications include fraud detection in financial transactions and anomaly detection in sensor networks. On the other hand, global outlier detection is more appropriate in situations where the anomalous behavior is spread out across the entire dataset and represents a significant departure from the normal behavior. Examples of such applications include outlier detection in medical studies and network intrusion detection.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
